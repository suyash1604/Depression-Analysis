{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, MaxPooling1D, Conv1D, Dropout\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input, TimeDistributed, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/aud_features_BoAW_openSMILE_230_MFCC/y_train_BoAW_openSMILE_230_MFCC.gz', delimiter=',')\n",
    "y_dev = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/aud_features_BoAW_openSMILE_230_MFCC/y_dev_BoAW_openSMILE_230_MFCC.gz', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 29679, 101)\n",
      "(56, 29679, 101)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/aud_features_BoAW_openSMILE_230_MFCC/x_train_BoAW_openSMILE_230_MFCC.gz', delimiter=',').reshape(163, 19579, 101)\n",
    "x_dev = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/aud_features_BoAW_openSMILE_230_MFCC/x_dev_BoAW_openSMILE_230_MFCC.gz', delimiter=',').reshape(56, 29679, 101)\n",
    "\n",
    "x_train_input_shape = x_train.shape\n",
    "x_dev_input_shape = x_dev.shape\n",
    "\n",
    "zeros = np.zeros((163, x_dev_input_shape[1]-x_train_input_shape[1], x_train_input_shape[2]))\n",
    "\n",
    "# adding rows with value 0 to make the dimensions of x_train and x_dev equal\n",
    "x_train = np.concatenate((x_train, zeros), axis=1)\n",
    "\n",
    "x_train_input_shape = x_train.shape\n",
    "x_dev_input_shape = x_dev.shape\n",
    "\n",
    "print(x_train_input_shape)\n",
    "print(x_dev_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 29679, 16)         4864      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 29679, 16)        64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 29679, 16)         0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 14840, 16)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 14840, 32)         1568      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 14840, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14840, 32)         0         \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 7420, 32)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 7420, 64)          6208      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 7420, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7420, 64)          0         \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 3710, 64)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 3710, 128)         24704     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 3710, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3710, 128)         0         \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 1855, 128)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 1855, 32)          20608     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 1855, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1855, 32)          0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 1855, 16)          3136      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 1855, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1855, 16)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 29680)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 29681     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,921\n",
      "Trainable params: 91,345\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\"\"\"\n",
    "    Default values of Batch Normalization are:\n",
    "        Momentum defaults to 0.99\n",
    "        The hyperparameter ε defaults to 0.001\n",
    "        The hyperparameter β defaults to an all-zeros vector\n",
    "        The hyperparameter γ defaults to an all-ones vector\n",
    "\"\"\"\n",
    "\n",
    "model.add(Conv1D(16, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "model.add(Conv1D(32, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "model.add(Conv1D(64, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "model.add(Conv1D(128, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
    "                    bias_regularizer=regularizers.L2(1e-4), \n",
    "                    activity_regularizer=regularizers.L2(1e-5), \n",
    "                    activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1772 - accuracy: 0.6135\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21429, saving model to /Users/nitanshjain/Documents/Miscellaneous/Depression_Analysis/Model_Checkpoints/BoAW_OpenSmile/weights-improvement-BatchNormalization-Dropout-01-0.21.hdf5\n",
      "6/6 [==============================] - 47s 6s/step - loss: 1.1772 - accuracy: 0.6135 - val_loss: 2.6510 - val_accuracy: 0.2143\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7115 - accuracy: 0.7239\n",
      "Epoch 2: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 33s 6s/step - loss: 0.7115 - accuracy: 0.7239 - val_loss: 2.6658 - val_accuracy: 0.2143\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7994 - accuracy: 0.7301\n",
      "Epoch 3: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.7994 - accuracy: 0.7301 - val_loss: 3.0134 - val_accuracy: 0.2143\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1260 - accuracy: 0.7730\n",
      "Epoch 4: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 27s 5s/step - loss: 1.1260 - accuracy: 0.7730 - val_loss: 3.9324 - val_accuracy: 0.2143\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9224 - accuracy: 0.7055\n",
      "Epoch 5: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 32s 6s/step - loss: 0.9224 - accuracy: 0.7055 - val_loss: 4.4462 - val_accuracy: 0.2143\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8065 - accuracy: 0.6748\n",
      "Epoch 6: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 34s 5s/step - loss: 0.8065 - accuracy: 0.6748 - val_loss: 4.1523 - val_accuracy: 0.2143\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.7239\n",
      "Epoch 7: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.6259 - accuracy: 0.7239 - val_loss: 4.0892 - val_accuracy: 0.2143\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9732 - accuracy: 0.6380\n",
      "Epoch 8: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.9732 - accuracy: 0.6380 - val_loss: 5.5823 - val_accuracy: 0.2143\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5871 - accuracy: 0.7914\n",
      "Epoch 9: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5871 - accuracy: 0.7914 - val_loss: 6.2608 - val_accuracy: 0.2143\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.7791\n",
      "Epoch 10: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5583 - accuracy: 0.7791 - val_loss: 6.1408 - val_accuracy: 0.2143\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8098\n",
      "Epoch 11: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.5170 - accuracy: 0.8098 - val_loss: 5.4348 - val_accuracy: 0.2143\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.8037\n",
      "Epoch 12: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.5954 - accuracy: 0.8037 - val_loss: 5.1648 - val_accuracy: 0.2143\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.8282\n",
      "Epoch 13: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.3899 - accuracy: 0.8282 - val_loss: 5.7197 - val_accuracy: 0.2143\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6760 - accuracy: 0.7853\n",
      "Epoch 14: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6760 - accuracy: 0.7853 - val_loss: 4.3750 - val_accuracy: 0.2143\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.7730\n",
      "Epoch 15: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 53s 9s/step - loss: 0.4397 - accuracy: 0.7730 - val_loss: 2.8158 - val_accuracy: 0.2143\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8167 - accuracy: 0.7914\n",
      "Epoch 16: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 50s 8s/step - loss: 0.8167 - accuracy: 0.7914 - val_loss: 4.5637 - val_accuracy: 0.2143\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8344\n",
      "Epoch 17: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 46s 8s/step - loss: 0.3777 - accuracy: 0.8344 - val_loss: 5.6821 - val_accuracy: 0.2143\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.7975\n",
      "Epoch 18: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 34s 6s/step - loss: 0.3911 - accuracy: 0.7975 - val_loss: 6.8738 - val_accuracy: 0.2143\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.7362\n",
      "Epoch 19: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 33s 5s/step - loss: 0.5970 - accuracy: 0.7362 - val_loss: 8.8609 - val_accuracy: 0.2143\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.7791\n",
      "Epoch 20: val_accuracy did not improve from 0.21429\n",
      "6/6 [==============================] - 36s 5s/step - loss: 0.6707 - accuracy: 0.7791 - val_loss: 11.9531 - val_accuracy: 0.2143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1373ea260>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "checkpoint_filepath = '/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Model_Checkpoints/BoAW_OpenSmile/weights-improvement-BatchNormalization-Dropout-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=20,\n",
    "            callbacks=[model_checkpoint_callback],\n",
    "            validation_data=(x_dev, y_dev),\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "Epoch 15/20\n",
    "6/6 [==============================] - 315s 52s/step - loss: 0.5692 - accuracy: 0.7178 - val_loss: 0.6434 - val_accuracy: 0.7857"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
