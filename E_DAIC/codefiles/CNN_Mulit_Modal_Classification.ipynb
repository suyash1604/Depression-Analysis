{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 20:56:28.557011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Flatten, Dense, Input, concatenate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bovw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoVW/Classification/y_train_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',')\n",
    "y_dev_bovw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoVW/Classification/y_dev_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',')\n",
    "\n",
    "y_train_boaw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoAW/Classification/y_train_BoAW_openSMILE_230_MFCC.gz', delimiter=',')\n",
    "y_dev_boaw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoAW/Classification/y_dev_BoAW_openSMILE_230_MFCC.gz', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 36277, 100)\n",
      "(56, 36277, 100)\n"
     ]
    }
   ],
   "source": [
    "# BoVW_openFace_210_Pose_Gaze_AUs\n",
    "# Data Handling\n",
    "\n",
    "x_train_bovw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoVW/x_train_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',').reshape(163, 19663, 100)\n",
    "x_dev_bovw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoVW/x_dev_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',').reshape(56, 36277, 100)\n",
    "\n",
    "x_train_bovw_input_shape = x_train_bovw.shape\n",
    "x_dev_bovw_input_shape = x_dev_bovw.shape\n",
    "\n",
    "zeros = np.zeros((163, x_dev_bovw_input_shape[1]-x_train_bovw_input_shape[1], x_train_bovw_input_shape[2]))\n",
    "\n",
    "# adding rows with value 0 to make the dimensions of x_train_bovw and x_dev_bovw equal\n",
    "x_train_bovw = np.concatenate((x_train_bovw, zeros), axis=1)\n",
    "\n",
    "print(x_train_bovw.shape)\n",
    "print(x_dev_bovw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 29679, 100)\n",
      "(56, 29679, 100)\n"
     ]
    }
   ],
   "source": [
    "# BoAW_openSMILE_230_MFCC\n",
    "# Data Handling\n",
    "x_train_boaw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoAW/x_train_BoAW_openSMILE_230_MFCC.gz', delimiter=',').reshape(163, 19579, 100)\n",
    "x_dev_boaw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoAW/x_dev_BoAW_openSMILE_230_MFCC.gz', delimiter=',').reshape(56, 29679, 100)\n",
    "\n",
    "x_train_boaw_input_shape = x_train_boaw.shape\n",
    "x_dev_boaw_input_shape = x_dev_boaw.shape\n",
    "\n",
    "zeros = np.zeros((163, x_dev_boaw_input_shape[1]-x_train_boaw_input_shape[1], x_train_boaw_input_shape[2]))\n",
    "\n",
    "# adding rows with value 0 to make the dimensions of x_train_boaw and x_dev_boaw equal\n",
    "x_train_boaw = np.concatenate((x_train_boaw, zeros), axis=1)\n",
    "\n",
    "print(x_train_boaw.shape)\n",
    "print(x_dev_boaw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 36277, 100)\n",
      "(56, 36277, 100)\n"
     ]
    }
   ],
   "source": [
    "x_train_bovw_input_shape = x_train_bovw.shape\n",
    "x_train_boaw_input_shape = x_train_boaw.shape\n",
    "\n",
    "train_zeros = np.zeros((163, x_train_bovw_input_shape[1]-x_train_boaw_input_shape[1], x_train_bovw_input_shape[2]))\n",
    "dev_zeros = np.zeros((56, x_dev_bovw_input_shape[1]-x_dev_boaw_input_shape[1], x_dev_bovw_input_shape[2]))\n",
    "\n",
    "\n",
    "x_train_boaw = np.concatenate((x_train_boaw, train_zeros), axis=1)\n",
    "x_dev_boaw = np.concatenate((x_dev_boaw, dev_zeros), axis=1)\n",
    "\n",
    "print(x_train_boaw.shape)\n",
    "print(x_dev_boaw.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 21:01:07.885600: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 36277, 100)]      0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 36277, 100)        30100     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 36277, 100)       400       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 36277, 100)        0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 7256, 100)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 7256, 64)          19264     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7256, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7256, 64)          0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 1452, 64)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1452, 32)          6176      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1452, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1452, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 291, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 291, 16)           1552      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 291, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 291, 16)           0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 59, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,940\n",
      "Trainable params: 57,516\n",
      "Non-trainable params: 424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BoVW OpenFace\n",
    "inputs_openFace = Input(shape=x_train_bovw.shape[1:])\n",
    "c1 = Conv1D(100, (3), padding='same', activation='relu')(inputs_openFace)\n",
    "bn1 = BatchNormalization()(c1)\n",
    "d1 = Dropout(rate=0.8)(bn1)\n",
    "mp1 = MaxPooling1D(pool_size=(5), padding='same')(d1)\n",
    "\n",
    "c2 = Conv1D(64, (3), padding='same', activation='relu')(mp1)\n",
    "bn2 = BatchNormalization()(c2)\n",
    "d2 = Dropout(rate=0.5)(bn2)\n",
    "mp2 = MaxPooling1D(pool_size=(5), padding='same')(d2)\n",
    "\n",
    "c3 = Conv1D(32, (3), padding='same', activation='relu')(mp2)\n",
    "bn3 = BatchNormalization()(c3)\n",
    "d3 = Dropout(rate=0.5)(bn3)\n",
    "mp3 = MaxPooling1D(pool_size=(5), padding='same')(d3)\n",
    "\n",
    "c4 = Conv1D(16, (3), padding='same', activation='relu')(mp3)\n",
    "bn4 = BatchNormalization()(c4)\n",
    "d4 = Dropout(rate=0.5)(bn4)\n",
    "flat_openFace = MaxPooling1D(pool_size=(5), padding='same')(d4)\n",
    "\n",
    "\n",
    "model_openFace = Model(inputs=inputs_openFace, outputs=flat_openFace)\n",
    "model_openFace.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 36277, 100)]      0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 36277, 100)        30100     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 36277, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 36277, 100)        0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 7256, 100)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 7256, 64)          19264     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 7256, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7256, 64)          0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 1452, 64)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 1452, 32)          6176      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 1452, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1452, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 291, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 291, 16)           1552      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 291, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 291, 16)           0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 59, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,940\n",
      "Trainable params: 57,516\n",
      "Non-trainable params: 424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BoVW OpenSmile\n",
    "inputs_openSmile = Input(shape=x_train_bovw.shape[1:])\n",
    "c5 = Conv1D(100, (3), padding='same', activation='relu')(inputs_openSmile)\n",
    "bn5 = BatchNormalization()(c5)\n",
    "d5 = Dropout(rate=0.8)(bn5)\n",
    "mp5 = MaxPooling1D(pool_size=(5), padding='same')(d5)\n",
    "\n",
    "c6 = Conv1D(64, (3), padding='same', activation='relu')(mp5)\n",
    "bn6 = BatchNormalization()(c6)\n",
    "d6 = Dropout(rate=0.5)(bn6)\n",
    "mp6 = MaxPooling1D(pool_size=(5), padding='same')(d6)\n",
    "\n",
    "c7 = Conv1D(32, (3), padding='same', activation='relu')(mp6)\n",
    "bn7 = BatchNormalization()(c7)\n",
    "d7 = Dropout(rate=0.5)(bn7)\n",
    "mp7 = MaxPooling1D(pool_size=(5), padding='same')(d7)\n",
    "\n",
    "c8 = Conv1D(16, (3), padding='same', activation='relu')(mp7)\n",
    "bn8 = BatchNormalization()(c8)\n",
    "d8 = Dropout(rate=0.5)(bn8)\n",
    "flat_openSmile = MaxPooling1D(pool_size=(5), padding='same')(d8)\n",
    "\n",
    "model_openSmile = Model(inputs=inputs_openSmile, outputs=flat_openSmile)\n",
    "model_openSmile.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Modal (BoVW OpenFace and BoAW OpenSmile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 36277, 100)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 36277, 100)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 36277, 100)   30100       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 36277, 100)   30100       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 36277, 100)  400         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 36277, 100)  400         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 36277, 100)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 36277, 100)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 7256, 100)    0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 7256, 100)   0           ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 7256, 64)     19264       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 7256, 64)     19264       ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 7256, 64)    256         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 7256, 64)    256         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 7256, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 7256, 64)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 1452, 64)    0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 1452, 64)    0           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 1452, 32)     6176        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 1452, 32)     6176        ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1452, 32)    128         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 1452, 32)    128         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1452, 32)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 1452, 32)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 291, 32)     0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 291, 32)     0           ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 291, 16)      1552        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 291, 16)      1552        ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 291, 16)     64          ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 291, 16)     64          ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 291, 16)      0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 291, 16)      0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 59, 16)      0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 59, 16)      0           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 118, 16)      0           ['max_pooling1d_3[0][0]',        \n",
      "                                                                  'max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 118, 16)      2112        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 118, 16)     64          ['lstm[0][0]']                   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 118, 16)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 24, 16)      0           ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 24, 1)        72          ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 24, 1)       4           ['lstm_1[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 24, 1)        0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 24, 1)        2           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 24, 1)        0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 24)           0           ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            25          ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 118,159\n",
      "Trainable params: 117,277\n",
      "Non-trainable params: 882\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = concatenate([flat_openFace, flat_openSmile], axis=1)\n",
    "\n",
    "l1 = LSTM(16, return_sequences=True)(x)\n",
    "bn9 = BatchNormalization()(l1)\n",
    "d9 = Dropout(rate=0.5)(bn9)\n",
    "mp9 = MaxPooling1D(pool_size=(5), padding='same')(d9)\n",
    "\n",
    "l2 = LSTM(1, return_sequences=True)(mp9)\n",
    "bn10 = BatchNormalization()(l2)\n",
    "d10 = Dropout(rate=0.5)(bn10)\n",
    "\n",
    "den1 = Dense(1, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
    "                    bias_regularizer=regularizers.L2(1e-4), \n",
    "                    activity_regularizer=regularizers.L2(1e-5), \n",
    "                    activation='relu')(d10)\n",
    "d11 = Dropout(rate=0.2)(den1)\n",
    "\n",
    "f1 = Flatten()(d11)\n",
    "output = Dense(1, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
    "                    bias_regularizer=regularizers.L2(1e-4), \n",
    "                    activity_regularizer=regularizers.L2(1e-5), \n",
    "                    activation='sigmoid')(f1)\n",
    "\n",
    "final_model = Model(inputs=[inputs_openFace, inputs_openSmile], outputs=[output])\n",
    "\n",
    "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
    "final_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "6/6 [==============================] - 130s 18s/step - loss: 0.7014 - accuracy: 0.4233 - val_loss: 0.6940 - val_accuracy: 0.2321\n",
      "Epoch 2/80\n",
      "6/6 [==============================] - 95s 15s/step - loss: 0.7089 - accuracy: 0.4294 - val_loss: 0.6936 - val_accuracy: 0.4464\n",
      "Epoch 3/80\n",
      "6/6 [==============================] - 66s 10s/step - loss: 0.7030 - accuracy: 0.4908 - val_loss: 0.6930 - val_accuracy: 0.5893\n",
      "Epoch 4/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7074 - accuracy: 0.4417 - val_loss: 0.6923 - val_accuracy: 0.7500\n",
      "Epoch 5/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7147 - accuracy: 0.4417 - val_loss: 0.6916 - val_accuracy: 0.7857\n",
      "Epoch 6/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7185 - accuracy: 0.3926 - val_loss: 0.6909 - val_accuracy: 0.7857\n",
      "Epoch 7/80\n",
      "6/6 [==============================] - 64s 10s/step - loss: 0.7097 - accuracy: 0.3988 - val_loss: 0.6902 - val_accuracy: 0.7857\n",
      "Epoch 8/80\n",
      "6/6 [==============================] - 68s 11s/step - loss: 0.7102 - accuracy: 0.4847 - val_loss: 0.6896 - val_accuracy: 0.7857\n",
      "Epoch 9/80\n",
      "6/6 [==============================] - 77s 12s/step - loss: 0.7110 - accuracy: 0.4417 - val_loss: 0.6889 - val_accuracy: 0.7857\n",
      "Epoch 10/80\n",
      "6/6 [==============================] - 77s 12s/step - loss: 0.7041 - accuracy: 0.5092 - val_loss: 0.6882 - val_accuracy: 0.7857\n",
      "Epoch 11/80\n",
      "6/6 [==============================] - 74s 12s/step - loss: 0.6947 - accuracy: 0.4601 - val_loss: 0.6875 - val_accuracy: 0.7857\n",
      "Epoch 12/80\n",
      "6/6 [==============================] - 75s 12s/step - loss: 0.7233 - accuracy: 0.3742 - val_loss: 0.6867 - val_accuracy: 0.7857\n",
      "Epoch 13/80\n",
      "6/6 [==============================] - 74s 12s/step - loss: 0.7091 - accuracy: 0.4294 - val_loss: 0.6860 - val_accuracy: 0.7857\n",
      "Epoch 14/80\n",
      "6/6 [==============================] - 72s 12s/step - loss: 0.7193 - accuracy: 0.4172 - val_loss: 0.6853 - val_accuracy: 0.7857\n",
      "Epoch 15/80\n",
      "6/6 [==============================] - 67s 11s/step - loss: 0.7058 - accuracy: 0.4417 - val_loss: 0.6845 - val_accuracy: 0.7857\n",
      "Epoch 16/80\n",
      "6/6 [==============================] - 66s 11s/step - loss: 0.6950 - accuracy: 0.5031 - val_loss: 0.6837 - val_accuracy: 0.7857\n",
      "Epoch 17/80\n",
      "6/6 [==============================] - 69s 11s/step - loss: 0.7159 - accuracy: 0.4172 - val_loss: 0.6829 - val_accuracy: 0.7857\n",
      "Epoch 18/80\n",
      "6/6 [==============================] - 68s 11s/step - loss: 0.7103 - accuracy: 0.4724 - val_loss: 0.6822 - val_accuracy: 0.7857\n",
      "Epoch 19/80\n",
      "6/6 [==============================] - 67s 11s/step - loss: 0.7078 - accuracy: 0.4969 - val_loss: 0.6814 - val_accuracy: 0.7857\n",
      "Epoch 20/80\n",
      "6/6 [==============================] - 66s 10s/step - loss: 0.7018 - accuracy: 0.5031 - val_loss: 0.6807 - val_accuracy: 0.7857\n",
      "Epoch 21/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7218 - accuracy: 0.4356 - val_loss: 0.6800 - val_accuracy: 0.7857\n",
      "Epoch 22/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7024 - accuracy: 0.4663 - val_loss: 0.6793 - val_accuracy: 0.7857\n",
      "Epoch 23/80\n",
      "6/6 [==============================] - 64s 10s/step - loss: 0.7012 - accuracy: 0.5092 - val_loss: 0.6787 - val_accuracy: 0.7857\n",
      "Epoch 24/80\n",
      "6/6 [==============================] - 73s 11s/step - loss: 0.7174 - accuracy: 0.4785 - val_loss: 0.6781 - val_accuracy: 0.7857\n",
      "Epoch 25/80\n",
      "6/6 [==============================] - 65s 10s/step - loss: 0.7022 - accuracy: 0.4908 - val_loss: 0.6775 - val_accuracy: 0.7857\n",
      "Epoch 26/80\n",
      "6/6 [==============================] - 66s 11s/step - loss: 0.7123 - accuracy: 0.4233 - val_loss: 0.6770 - val_accuracy: 0.7857\n",
      "Epoch 27/80\n",
      "6/6 [==============================] - 64s 10s/step - loss: 0.7103 - accuracy: 0.4724 - val_loss: 0.6766 - val_accuracy: 0.7857\n",
      "Epoch 28/80\n",
      "6/6 [==============================] - 65s 10s/step - loss: 0.7124 - accuracy: 0.4233 - val_loss: 0.6764 - val_accuracy: 0.7857\n",
      "Epoch 29/80\n",
      "6/6 [==============================] - 66s 11s/step - loss: 0.7091 - accuracy: 0.4601 - val_loss: 0.6763 - val_accuracy: 0.7857\n",
      "Epoch 30/80\n",
      "6/6 [==============================] - 68s 11s/step - loss: 0.6990 - accuracy: 0.4663 - val_loss: 0.6763 - val_accuracy: 0.7857\n",
      "Epoch 31/80\n",
      "6/6 [==============================] - 65s 10s/step - loss: 0.7132 - accuracy: 0.3988 - val_loss: 0.6766 - val_accuracy: 0.7857\n",
      "Epoch 32/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7188 - accuracy: 0.4110 - val_loss: 0.6771 - val_accuracy: 0.7857\n",
      "Epoch 33/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7134 - accuracy: 0.4663 - val_loss: 0.6780 - val_accuracy: 0.7857\n",
      "Epoch 34/80\n",
      "6/6 [==============================] - 64s 10s/step - loss: 0.7094 - accuracy: 0.4110 - val_loss: 0.6791 - val_accuracy: 0.7857\n",
      "Epoch 35/80\n",
      "6/6 [==============================] - 68s 11s/step - loss: 0.7014 - accuracy: 0.4172 - val_loss: 0.6806 - val_accuracy: 0.7857\n",
      "Epoch 36/80\n",
      "6/6 [==============================] - 67s 11s/step - loss: 0.6990 - accuracy: 0.4724 - val_loss: 0.6824 - val_accuracy: 0.7679\n",
      "Epoch 37/80\n",
      "6/6 [==============================] - 67s 11s/step - loss: 0.6966 - accuracy: 0.4601 - val_loss: 0.6844 - val_accuracy: 0.7500\n",
      "Epoch 38/80\n",
      "6/6 [==============================] - 67s 11s/step - loss: 0.7102 - accuracy: 0.4663 - val_loss: 0.6862 - val_accuracy: 0.6786\n",
      "Epoch 39/80\n",
      "6/6 [==============================] - 64s 10s/step - loss: 0.7061 - accuracy: 0.4540 - val_loss: 0.6886 - val_accuracy: 0.6429\n",
      "Epoch 40/80\n",
      "6/6 [==============================] - 65s 10s/step - loss: 0.7059 - accuracy: 0.4785 - val_loss: 0.6905 - val_accuracy: 0.5357\n",
      "Epoch 41/80\n",
      "6/6 [==============================] - 67s 11s/step - loss: 0.7062 - accuracy: 0.4601 - val_loss: 0.6921 - val_accuracy: 0.5357\n",
      "Epoch 42/80\n",
      "6/6 [==============================] - 68s 11s/step - loss: 0.7058 - accuracy: 0.4663 - val_loss: 0.6934 - val_accuracy: 0.5179\n",
      "Epoch 43/80\n",
      "6/6 [==============================] - 71s 11s/step - loss: 0.7050 - accuracy: 0.4724 - val_loss: 0.6946 - val_accuracy: 0.5179\n",
      "Epoch 44/80\n",
      "6/6 [==============================] - 69s 11s/step - loss: 0.7083 - accuracy: 0.4601 - val_loss: 0.6954 - val_accuracy: 0.5357\n",
      "Epoch 45/80\n",
      "6/6 [==============================] - 69s 11s/step - loss: 0.7115 - accuracy: 0.4479 - val_loss: 0.6956 - val_accuracy: 0.5357\n",
      "Epoch 46/80\n",
      "6/6 [==============================] - 314s 60s/step - loss: 0.7046 - accuracy: 0.4479 - val_loss: 0.6956 - val_accuracy: 0.5357\n",
      "Epoch 47/80\n",
      "6/6 [==============================] - 71s 10s/step - loss: 0.7021 - accuracy: 0.4724 - val_loss: 0.6957 - val_accuracy: 0.5536\n",
      "Epoch 48/80\n",
      "6/6 [==============================] - 67s 11s/step - loss: 0.7086 - accuracy: 0.4294 - val_loss: 0.6958 - val_accuracy: 0.5536\n",
      "Epoch 49/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7100 - accuracy: 0.4049 - val_loss: 0.6959 - val_accuracy: 0.5536\n",
      "Epoch 50/80\n",
      "6/6 [==============================] - 65s 11s/step - loss: 0.7200 - accuracy: 0.3558 - val_loss: 0.6961 - val_accuracy: 0.5714\n",
      "Epoch 51/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7105 - accuracy: 0.4356 - val_loss: 0.6963 - val_accuracy: 0.5714\n",
      "Epoch 52/80\n",
      "6/6 [==============================] - 75s 12s/step - loss: 0.7047 - accuracy: 0.3926 - val_loss: 0.6965 - val_accuracy: 0.5536\n",
      "Epoch 53/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7029 - accuracy: 0.4663 - val_loss: 0.6969 - val_accuracy: 0.5536\n",
      "Epoch 54/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7010 - accuracy: 0.5092 - val_loss: 0.6974 - val_accuracy: 0.5714\n",
      "Epoch 55/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7130 - accuracy: 0.3926 - val_loss: 0.6978 - val_accuracy: 0.5714\n",
      "Epoch 56/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7012 - accuracy: 0.4540 - val_loss: 0.6981 - val_accuracy: 0.5714\n",
      "Epoch 57/80\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6984 - accuracy: 0.4724 - val_loss: 0.6983 - val_accuracy: 0.5000\n",
      "Epoch 58/80\n",
      "6/6 [==============================] - 57s 9s/step - loss: 0.7081 - accuracy: 0.4356 - val_loss: 0.6983 - val_accuracy: 0.4821\n",
      "Epoch 59/80\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7050 - accuracy: 0.4356 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 60/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7017 - accuracy: 0.4724 - val_loss: 0.6985 - val_accuracy: 0.4643\n",
      "Epoch 61/80\n",
      "6/6 [==============================] - 66s 10s/step - loss: 0.7055 - accuracy: 0.4540 - val_loss: 0.6981 - val_accuracy: 0.4821\n",
      "Epoch 62/80\n",
      "6/6 [==============================] - 64s 10s/step - loss: 0.6997 - accuracy: 0.4908 - val_loss: 0.6979 - val_accuracy: 0.4643\n",
      "Epoch 63/80\n",
      "6/6 [==============================] - 67s 11s/step - loss: 0.7126 - accuracy: 0.3926 - val_loss: 0.6975 - val_accuracy: 0.4643\n",
      "Epoch 64/80\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7008 - accuracy: 0.4663 - val_loss: 0.6969 - val_accuracy: 0.5179\n",
      "Epoch 65/80\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7013 - accuracy: 0.4847 - val_loss: 0.6965 - val_accuracy: 0.5000\n",
      "Epoch 66/80\n",
      "6/6 [==============================] - 65s 10s/step - loss: 0.7186 - accuracy: 0.4294 - val_loss: 0.6962 - val_accuracy: 0.5357\n",
      "Epoch 67/80\n",
      "6/6 [==============================] - 68s 11s/step - loss: 0.7147 - accuracy: 0.4785 - val_loss: 0.6958 - val_accuracy: 0.5536\n",
      "Epoch 68/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7082 - accuracy: 0.4724 - val_loss: 0.6953 - val_accuracy: 0.5893\n",
      "Epoch 69/80\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6996 - accuracy: 0.4479 - val_loss: 0.6951 - val_accuracy: 0.6071\n",
      "Epoch 70/80\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7069 - accuracy: 0.4663 - val_loss: 0.6950 - val_accuracy: 0.6071\n",
      "Epoch 71/80\n",
      "6/6 [==============================] - 64s 10s/step - loss: 0.7068 - accuracy: 0.4969 - val_loss: 0.6949 - val_accuracy: 0.6071\n",
      "Epoch 72/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7024 - accuracy: 0.4479 - val_loss: 0.6947 - val_accuracy: 0.6071\n",
      "Epoch 73/80\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7037 - accuracy: 0.5337 - val_loss: 0.6945 - val_accuracy: 0.6250\n",
      "Epoch 74/80\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6934 - accuracy: 0.5276 - val_loss: 0.6948 - val_accuracy: 0.6071\n",
      "Epoch 75/80\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7055 - accuracy: 0.4479 - val_loss: 0.6948 - val_accuracy: 0.6071\n",
      "Epoch 76/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7110 - accuracy: 0.4172 - val_loss: 0.6950 - val_accuracy: 0.6429\n",
      "Epoch 77/80\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7082 - accuracy: 0.3926 - val_loss: 0.6954 - val_accuracy: 0.5893\n",
      "Epoch 78/80\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7019 - accuracy: 0.4540 - val_loss: 0.6956 - val_accuracy: 0.5714\n",
      "Epoch 79/80\n",
      "6/6 [==============================] - 66s 11s/step - loss: 0.7032 - accuracy: 0.4785 - val_loss: 0.6958 - val_accuracy: 0.5536\n",
      "Epoch 80/80\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7118 - accuracy: 0.4479 - val_loss: 0.6960 - val_accuracy: 0.5179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1315fff10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "checkpoint_filepath = '/Users/suyashsingh/Documents/Projects/Depression_Analysis/checkpoints/multimodal_classification/weights-improvement-multimodal-hdf5-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='max'\n",
    "    )\n",
    "\n",
    "final_model.fit(x=[x_train_bovw, x_train_boaw],\n",
    "                y=y_train_bovw,\n",
    "                batch_size=batch_size,\n",
    "                epochs=80,\n",
    "                callbacks=[model_checkpoint_callback],\n",
    "                validation_data=[[x_dev_bovw, x_dev_boaw], y_dev_bovw],\n",
    "                shuffle=True,\n",
    "                verbose=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/Users/suyashsingh/Documents/Projects/Depression_Analysis/checkpoints/multimodal_classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 36277, 100)\n",
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "x_test_bovw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoVW/x_test_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',').reshape(56, 16869, 100)\n",
    "y_test_bovw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoVW/Classification/y_test_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',')\n",
    "\n",
    "x_test_bovw_input_shape = x_test_bovw.shape\n",
    "y_test_bovw_input_shape = y_test_bovw.shape\n",
    "\n",
    "zeros_bovw = np.zeros((56, x_dev_bovw_input_shape[1]-x_test_bovw_input_shape[1], x_test_bovw_input_shape[2]))\n",
    "\n",
    "# adding rows with value 0 to make the dimensions of x_test_bovw and x_dev equal\n",
    "x_test_bovw = np.concatenate((x_test_bovw, zeros_bovw), axis=1)\n",
    "\n",
    "x_test_bovw_input_shape = x_test_bovw.shape\n",
    "\n",
    "print(x_test_bovw_input_shape)\n",
    "print(y_test_bovw_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 36277, 100)\n",
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "x_test_boaw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoAW/x_test_BoAW_openSMILE_230_MFCC.gz', delimiter=',').reshape(56, 16674, 100)\n",
    "y_test_boaw = np.loadtxt('/Users/suyashsingh/Documents/Projects/Depression_Analysis/data/BoAW/Classification/y_test_BoAW_openSMILE_230_MFCC.gz', delimiter=',')\n",
    "\n",
    "x_test_boaw_input_shape = x_test_boaw.shape\n",
    "y_test_boaw_input_shape = y_test_boaw.shape\n",
    "\n",
    "zeros_boaw = np.zeros((56, x_dev_bovw_input_shape[1]-x_test_boaw_input_shape[1], x_test_boaw_input_shape[2]))\n",
    "\n",
    "# adding rows with value 0 to make the dimensions of x_test_boaw and x_dev equal\n",
    "x_test_boaw = np.concatenate((x_test_boaw, zeros_boaw), axis=1)\n",
    "\n",
    "x_test_boaw_input_shape = x_test_boaw.shape\n",
    "\n",
    "print(x_test_boaw_input_shape)\n",
    "print(y_test_boaw_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6852575540542603\n",
      "Test accuracy: 0.6964285969734192\n"
     ]
    }
   ],
   "source": [
    "score = final_model.evaluate(x=[x_test_bovw, x_test_boaw], y=y_test_bovw, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 11s 1s/step\n",
      "[[0.48921442]\n",
      " [0.48868152]\n",
      " [0.4891607 ]\n",
      " [0.4916366 ]\n",
      " [0.49022624]\n",
      " [0.4887184 ]\n",
      " [0.48925307]\n",
      " [0.48941568]\n",
      " [0.4893601 ]\n",
      " [0.48965356]\n",
      " [0.48967648]\n",
      " [0.49095806]\n",
      " [0.4887647 ]\n",
      " [0.4893425 ]\n",
      " [0.48891744]\n",
      " [0.48910555]\n",
      " [0.48888502]\n",
      " [0.4887632 ]\n",
      " [0.4890568 ]\n",
      " [0.48886707]\n",
      " [0.48897836]\n",
      " [0.48953474]\n",
      " [0.48972422]\n",
      " [0.48934114]\n",
      " [0.48965472]\n",
      " [0.4899695 ]\n",
      " [0.4892835 ]\n",
      " [0.49080852]\n",
      " [0.48962307]\n",
      " [0.48903063]\n",
      " [0.489894  ]\n",
      " [0.48903343]\n",
      " [0.4891791 ]\n",
      " [0.48868236]\n",
      " [0.48947564]\n",
      " [0.48872894]\n",
      " [0.4894623 ]\n",
      " [0.48914135]\n",
      " [0.48913994]\n",
      " [0.49005643]\n",
      " [0.48940971]\n",
      " [0.48975748]\n",
      " [0.48896483]\n",
      " [0.4899709 ]\n",
      " [0.4891355 ]\n",
      " [0.49024856]\n",
      " [0.49041328]\n",
      " [0.48898923]\n",
      " [0.48909026]\n",
      " [0.48943806]\n",
      " [0.48884046]\n",
      " [0.48899326]\n",
      " [0.49004114]\n",
      " [0.48966852]\n",
      " [0.49021357]\n",
      " [0.49034294]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = final_model.predict(x=[x_test_bovw, x_test_boaw])\n",
    "print(y_pred)\n",
    "print(y_test_bovw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Depression_Analysis-DHAu4qlc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4c57052e65c6ff5ccf4616eec21ba325df014e02c303eca8dc1b3f80d62bdca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
