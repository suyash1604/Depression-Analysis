{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BEC5aPNedRyV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, MaxPooling1D, Conv1D, Dropout\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input, TimeDistributed, LSTM, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pRgTxkFDeUnd"
      },
      "outputs": [],
      "source": [
        "y_train = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/vid_features_BoVW_openFace_210_Pose_Gaze_AUs/y_train_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',')\n",
        "y_dev = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/vid_features_BoVW_openFace_210_Pose_Gaze_AUs/y_dev_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3dvhT0PUn71m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(163, 36277, 101)\n",
            "(56, 36277, 101)\n"
          ]
        }
      ],
      "source": [
        "x_train = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/vid_features_BoVW_openFace_210_Pose_Gaze_AUs/x_train_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',').reshape(163, 19663, 101)\n",
        "x_dev = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/vid_features_BoVW_openFace_210_Pose_Gaze_AUs/x_dev_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',').reshape(56, 36277, 101)\n",
        "\n",
        "x_train_input_shape = x_train.shape\n",
        "x_dev_input_shape = x_dev.shape\n",
        "\n",
        "zeros = np.zeros((163, x_dev_input_shape[1]-x_train_input_shape[1], x_train_input_shape[2]))\n",
        "\n",
        "# adding rows with value 0 to make the dimensions of x_train and x_dev equal\n",
        "x_train = np.concatenate((x_train, zeros), axis=1)\n",
        "\n",
        "x_train_input_shape = x_train.shape\n",
        "x_dev_input_shape = x_dev.shape\n",
        "\n",
        "print(x_train_input_shape)\n",
        "print(x_dev_input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 36277, 16)         4864      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 36277, 16)        64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 36277, 16)         0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 18139, 16)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 18139, 32)         1568      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 18139, 32)        128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 18139, 32)         0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 9070, 32)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 9070, 64)          6208      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 9070, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 9070, 64)          0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 4535, 64)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 4535, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4535, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4535, 128)         0         \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 2268, 128)        0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 2268, 32)          20608     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 2268, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2268, 32)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 2268, 16)          3136      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 2268, 16)         64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 2268, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36288)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 36289     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 98,529\n",
            "Trainable params: 97,953\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\"\"\"\n",
        "    Default values of Batch Normalization are:\n",
        "        Momentum defaults to 0.99\n",
        "        The hyperparameter ε defaults to 0.001\n",
        "        The hyperparameter β defaults to an all-zeros vector\n",
        "        The hyperparameter γ defaults to an all-ones vector\n",
        "\"\"\"\n",
        "\n",
        "model.add(Conv1D(16, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
        "\n",
        "model.add(Conv1D(32, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
        "\n",
        "model.add(Conv1D(64, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
        "\n",
        "model.add(Conv1D(128, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
        "\n",
        "\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(LSTM(16, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
        "                    bias_regularizer=regularizers.L2(1e-4), \n",
        "                    activity_regularizer=regularizers.L2(1e-5), \n",
        "                    activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.2069 - accuracy: 0.6748\n",
            "Epoch 1: val_accuracy improved from -inf to 0.76786, saving model to /Users/nitanshjain/Documents/Miscellaneous/Depression_Analysis/Model_Checkpoints/BoVW_OpenFace/weights-improvement-BatchNormalization-Dropout-Regularization-01-0.77.hdf5\n",
            "6/6 [==============================] - 55s 8s/step - loss: 1.2069 - accuracy: 0.6748 - val_loss: 0.6832 - val_accuracy: 0.7679\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.3058 - accuracy: 0.6564\n",
            "Epoch 2: val_accuracy did not improve from 0.76786\n",
            "6/6 [==============================] - 39s 6s/step - loss: 1.3058 - accuracy: 0.6564 - val_loss: 0.6244 - val_accuracy: 0.7679\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.0087 - accuracy: 0.7669\n",
            "Epoch 3: val_accuracy did not improve from 0.76786\n",
            "6/6 [==============================] - 33s 5s/step - loss: 1.0087 - accuracy: 0.7669 - val_loss: 0.7149 - val_accuracy: 0.6071\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.0117 - accuracy: 0.7055\n",
            "Epoch 4: val_accuracy did not improve from 0.76786\n",
            "6/6 [==============================] - 36s 6s/step - loss: 1.0117 - accuracy: 0.7055 - val_loss: 0.6715 - val_accuracy: 0.7679\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.1563 - accuracy: 0.6074\n",
            "Epoch 5: val_accuracy did not improve from 0.76786\n",
            "6/6 [==============================] - 40s 7s/step - loss: 1.1563 - accuracy: 0.6074 - val_loss: 0.8295 - val_accuracy: 0.7679\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.8380 - accuracy: 0.7423\n",
            "Epoch 6: val_accuracy improved from 0.76786 to 0.78571, saving model to /Users/nitanshjain/Documents/Miscellaneous/Depression_Analysis/Model_Checkpoints/BoVW_OpenFace/weights-improvement-BatchNormalization-Dropout-Regularization-06-0.79.hdf5\n",
            "6/6 [==============================] - 40s 7s/step - loss: 0.8380 - accuracy: 0.7423 - val_loss: 0.7468 - val_accuracy: 0.7857\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.7607\n",
            "Epoch 7: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 34s 6s/step - loss: 0.8853 - accuracy: 0.7607 - val_loss: 1.0249 - val_accuracy: 0.7679\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.0171 - accuracy: 0.7669\n",
            "Epoch 8: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 33s 5s/step - loss: 1.0171 - accuracy: 0.7669 - val_loss: 0.5268 - val_accuracy: 0.7857\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.9269 - accuracy: 0.7178\n",
            "Epoch 9: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.9269 - accuracy: 0.7178 - val_loss: 0.9711 - val_accuracy: 0.7679\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.7222 - accuracy: 0.8098\n",
            "Epoch 10: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 32s 5s/step - loss: 0.7222 - accuracy: 0.8098 - val_loss: 0.6623 - val_accuracy: 0.7679\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.8037\n",
            "Epoch 11: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 32s 5s/step - loss: 0.5271 - accuracy: 0.8037 - val_loss: 0.6660 - val_accuracy: 0.7679\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5338 - accuracy: 0.8160\n",
            "Epoch 12: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.5338 - accuracy: 0.8160 - val_loss: 0.8185 - val_accuracy: 0.7679\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.8037\n",
            "Epoch 13: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.6075 - accuracy: 0.8037 - val_loss: 0.6047 - val_accuracy: 0.6964\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8466\n",
            "Epoch 14: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.4642 - accuracy: 0.8466 - val_loss: 0.7263 - val_accuracy: 0.7321\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.8712\n",
            "Epoch 15: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.4836 - accuracy: 0.8712 - val_loss: 0.7903 - val_accuracy: 0.7679\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.7975\n",
            "Epoch 16: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 32s 5s/step - loss: 0.5417 - accuracy: 0.7975 - val_loss: 1.6012 - val_accuracy: 0.7679\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.8607 - accuracy: 0.8221\n",
            "Epoch 17: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.8607 - accuracy: 0.8221 - val_loss: 1.3590 - val_accuracy: 0.4286\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.8037\n",
            "Epoch 18: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.6096 - accuracy: 0.8037 - val_loss: 0.9398 - val_accuracy: 0.7679\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.8650\n",
            "Epoch 19: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 29s 5s/step - loss: 0.4547 - accuracy: 0.8650 - val_loss: 0.9906 - val_accuracy: 0.7679\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.0232 - accuracy: 0.8344\n",
            "Epoch 20: val_accuracy did not improve from 0.78571\n",
            "6/6 [==============================] - 27s 4s/step - loss: 1.0232 - accuracy: 0.8344 - val_loss: 1.3885 - val_accuracy: 0.7679\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x167eab580>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "checkpoint_filepath = '/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Model_Checkpoints/BoVW_OpenFace/weights-improvement-BatchNormalization-Dropout-Regularization-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    # save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=20,\n",
        "            callbacks=[model_checkpoint_callback],\n",
        "            validation_data=(x_dev, y_dev),\n",
        "            shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x_test = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/vid_features_BoVW_openFace_210_Pose_Gaze_AUs/x_test_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',').reshape(56, 0, 101)\n",
        "# y_test = np.loadtxt('/Users/suyashsingh/Documents/Miscellaneous/Depression_Analysis/Data/vid_features_BoVW_openFace_210_Pose_Gaze_AUs/y_test_BoVW_openFace_210_Pose_Gaze_AUs.gz', delimiter=',')\n",
        "\n",
        "# x_test_input_shape = x_test.shape\n",
        "# y_test_input_shape = y_test.shape\n",
        "\n",
        "# zeros = np.zeros((56, x_dev_input_shape[1]-x_test_input_shape[1], x_test_input_shape[2]))\n",
        "\n",
        "# # adding rows with value 0 to make the dimensions of x_test and x_dev equal\n",
        "# x_test = np.concatenate((x_test, zeros), axis=1)\n",
        "\n",
        "# x_test_input_shape = x_test.shape\n",
        "\n",
        "# print(x_test_input_shape)\n",
        "# print(y_test_input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Models Accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Conv1D + MaxPooling1D + 2 LSTM Layers + Flatten + Dense + Adam Optimizer\n",
        "```\n",
        "Epoch 12/20\n",
        "6/6 [==============================] - 477s 80s/step - loss: 0.4566 - accuracy: 0.7975 - val_loss: 0.7239 - val_accuracy: 0.7857"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4 (v3.10.4:9d38120e33, Mar 23 2022, 17:29:05) [Clang 13.0.0 (clang-1300.0.29.30)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
