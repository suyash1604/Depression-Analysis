{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23495,"status":"ok","timestamp":1673372714826,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"MFSJUHt4FZ1y","outputId":"bde18eb0-e6e1-4d48-8fcd-205177b6cb46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n","Collecting sklearn\n","  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting hmmlearn\n","  Downloading hmmlearn-0.2.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (217 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.1/217.1 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting simplejson\n","  Downloading simplejson-3.18.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting eyed3\n","  Downloading eyed3-0.9.7-py3-none-any.whl (246 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.8/dist-packages (from hmmlearn) (1.0.2)\n","Collecting deprecation<3.0.0,>=2.1.0\n","  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n","Collecting filetype<2.0.0,>=1.0.7\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Collecting coverage[toml]<6.0.0,>=5.3.1\n","  Downloading coverage-5.5-cp38-cp38-manylinux2010_x86_64.whl (245 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from coverage[toml]<6.0.0,>=5.3.1->eyed3) (0.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from deprecation<3.0.0,>=2.1.0->eyed3) (21.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.16->hmmlearn) (3.1.0)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=9871a237a2ed2c8afabde459e50a4e6f0f60497d9b4bfab9a132d671c4659c17\n","  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n","Successfully built sklearn\n","Installing collected packages: sklearn, pydub, filetype, simplejson, coverage, deprecation, hmmlearn, eyed3\n","Successfully installed coverage-5.5 deprecation-2.1.0 eyed3-0.9.7 filetype-1.2.0 hmmlearn-0.2.8 pydub-0.25.1 simplejson-3.18.1 sklearn-0.0.post1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting boto\n","  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: boto\n","Successfully installed boto-2.49.0\n"]}],"source":["!pip3 install numpy matplotlib scipy sklearn hmmlearn simplejson eyed3 pydub\n","# !pip3 install pyAudioAnalysis\n","# !pip3 install plot_metrics\n","!pip3 install keras\n","!pip3 install boto"]},{"cell_type":"markdown","metadata":{"id":"_jZBuwG95euv"},"source":["Import all the required libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4776,"status":"ok","timestamp":1673372719595,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"lcmg15MTFPeN"},"outputs":[],"source":["import fnmatch\n","import os\n","import zipfile\n","import re\n","\n","import scipy.io.wavfile as wavfile\n","import wave\n","\n","import numpy as np\n","from numpy.lib import stride_tricks\n","import os\n","import tarfile\n","from PIL import Image\n","import scipy.io.wavfile as wav\n","\n","import pandas as pd\n","\n","import random\n","import boto\n","\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","# from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.utils import np_utils\n","from keras import backend as K"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21590,"status":"ok","timestamp":1673372741175,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"wO8NAIfVWIEZ","outputId":"534205a0-5e22-457f-c078-cc5a0314075c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":741,"status":"ok","timestamp":1673372741909,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"BkqydC5jCdid","outputId":"591e0213-8599-4345-ec97-a76f1e33cc76"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673372741911,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"Y9LOixzcaK2C"},"outputs":[],"source":["dir_name = '/content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data'\n","\n","# directory where audio and transcripts folders will be created\n","out_dir = '/content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data/raw'"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1673372741911,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"gcfVce2AhiEv"},"outputs":[],"source":["# !wget -r -np -nH --cut-dirs=3 -R index.html --user=daicwozuser --no-check-certificate https://dcapswoz.ict.usc.edu/wwwedaic/labels/"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":602,"status":"ok","timestamp":1673372742508,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"rJAWn68kNC6J"},"outputs":[],"source":["# /content/drive/MyDrive/Colab Notebooks/Depression Analysis/train_split.csv\n","train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Depression Analysis/train_split.csv')\n","\n","# /content/drive/MyDrive/Colab Notebooks/Depression Analysis/test_split.csv\n","test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Depression Analysis/test_split.csv')\n","\n","# /content/drive/MyDrive/Depression_Analysis_Research/dev_split.csv\n","dev_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Depression Analysis/dev_split.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":824,"status":"ok","timestamp":1673373848808,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"hB9dEEWANcw6","outputId":"38e3c283-1c70-4cde-a40e-4c42ab348089"},"outputs":[{"output_type":"stream","name":"stdout","text":["(163, 6)\n","(56, 6)\n","(56, 6)\n"]}],"source":["print(train_df.shape)\n","print(test_df.shape)\n","print(dev_df.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1673373849254,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"Yrp6HBqUvSR1","outputId":"f719cfea-0f89-4b0a-d5d8-e44b41e87698"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_df.head()    Participant_ID   Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity\n","0             302     male           0          4             0             28\n","1             303   female           0          0             0             17\n","2             304   female           0          6             0             20\n","3             305     male           0          7             0             28\n","4             307  female            0          4             0             23\n","test_df.head()    Participant_ID  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity\n","0             600  female           0          5             0           23.0\n","1             602  female           1         13             1           67.0\n","2             604    male           1         12             0           30.0\n","3             605    male           0          2             0           23.0\n","4             606  female           0          5             0           46.0\n","dev_df.head()    Participant_ID  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity\n","0             300    male           0          2             0             25\n","1             301    male           0          3             0             17\n","2             306  female           0          0             0             21\n","3             317    male           0          8             1             51\n","4             320  female           0         11             1             64\n"]}],"source":["print('train_df.head()', train_df.head())\n","print('test_df.head()', test_df.head())\n","print('dev_df.head()', dev_df.head())"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1673373850970,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"Y8iB5_RByxAV"},"outputs":[],"source":["def in_split(partic_id, df):\n","    \"\"\"\n","    Returns True if the participant is in the AVEC training split\n","    (aka participant's we have depression labels for)\n","    \"\"\"\n","    return partic_id in set(df['Participant_ID'].values)\n","\n","def get_depression_label(partic_id, df):\n","    \"\"\"\n","    Returns participant's PHQ8 Binary label. 1 representing depression;\n","    0 representing no depression.\n","    \"\"\"\n","    return df.loc[df['Participant_ID'] == partic_id]['PHQ_Score'].item()\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1673373852335,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"dNsnjk3cZx3g"},"outputs":[],"source":["def build_class_dictionaries(dir_name, df):\n","    \n","    print(\"dir name: \" + dir_name)\n","\n","    depressed_dict = dict()\n","    normal_dict = dict()\n","    \n","    for subdir, dirs, files in os.walk(dir_name):\n","        for file in files:\n","            if fnmatch.fnmatch(file, '*OpenSMILE2.3.0_mfcc.csv'):\n","                # print(file)\n","                regex = re.compile(r'\\d+')\n","                partic_id = [int(x) for x in regex.findall(file)][0]\n","\n","                if in_split(partic_id, df):\n","                    file_name = dir_name + '/' + str(partic_id) + '_P/features/' + file\n","                    # %cd dir_name\n","                    # print(type(file))\n","                    df_1 = pd.read_csv(file_name, delimiter=';')\n","                    df_1.drop(['name'], axis=1, inplace=True)\n","                    mat = np.mat(df_1)\n","\n","                    depressed = get_depression_label(partic_id, df)  # 1 if True\n","                    if depressed:\n","                        depressed_dict[partic_id] = mat\n","                    elif not depressed:\n","                        normal_dict[partic_id] = mat\n","    return depressed_dict, normal_dict"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":409689,"status":"ok","timestamp":1673374263356,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"aP1IN0JIZ7nw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2717a7a0-b17f-456f-a18d-10b0c25f3a2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["dir name: /content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data/raw/aud_features\n"]}],"source":["dir_name = '/content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data/raw/aud_features'\n","depressed_train_dict, normal_train_dict = build_class_dictionaries(dir_name, train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nPx9iaKZ-5_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"59de0173-17fc-4fcf-b4dc-b587e7d17cfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["dir name: /content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data/raw/aud_features\n"]}],"source":["dir_name = '/content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data/raw/aud_features'\n","depressed_test_dict, normal_test_dict = build_class_dictionaries(dir_name, test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJH8KifoPKEb"},"outputs":[],"source":["dir_name = '/content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data/raw/aud_features'\n","depressed_dev_dict, normal_dev_dict = build_class_dictionaries(dir_name, dev_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugYJ5ng0GwR9"},"outputs":[],"source":["del(dir_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-8b6RfpYZmA"},"outputs":[],"source":["print(len(depressed_train_dict))\n","print(len(normal_train_dict))\n","\n","print(len(depressed_test_dict))\n","print(len(normal_test_dict))\n","\n","print(len(depressed_dev_dict))\n","print(len(normal_dev_dict))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0e28axIV_NKh"},"outputs":[],"source":["def create_y_set(depressed_dict, normal_dict, df):\n","    \"\"\"\n","    Building an array that describes if a participant is depressed or not\n","    \"\"\"\n","    merged_dict = {**depressed_dict, **normal_dict}\n","\n","    y_func = list()\n","    part_id = list()\n","\n","    for id in df['Participant_ID']:\n","        part_id.append(id)\n","\n","    # print(len(part_id))\n","    for key, value in merged_dict.items():\n","        if key in part_id:\n","            # print(key)\n","            x = df.loc[df['Participant_ID']==key, 'PHQ_Binary'].iloc[0]\n","            y_func.append(x)    \n","    # print(df['Participant_ID'])\n","    # y_func = pd.DataFrame()\n","    return y_func, merged_dict\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-8ZSmt7JaYZ"},"outputs":[],"source":["y_train, merged_train_dict = create_y_set(depressed_train_dict, normal_train_dict, train_df)\n","print(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RAYyBjbdrz3"},"outputs":[],"source":["y_test, merged_test_dict = create_y_set(depressed_test_dict, normal_test_dict, test_df)\n","print(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSDbrwUGd2VX"},"outputs":[],"source":["y_dev, merged_dev_dict = create_y_set(depressed_dev_dict, normal_dev_dict, dev_df)\n","print(y_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HvefgLEH588"},"outputs":[],"source":["del(depressed_train_dict)\n","del(depressed_test_dict)\n","del(depressed_dev_dict)\n","del(normal_train_dict)\n","del(normal_test_dict)\n","del(normal_dev_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1669407297957,"user":{"displayName":"Nitansh Jain","userId":"16132165384365515816"},"user_tz":-330},"id":"4vs9uIiMebrY","outputId":"a9a876de-ce84-41c1-fd35-850a7a8bfad9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}],"source":["# x_train = np.array(list(merged_train_dict.values()))\n","# x_test = np.array(list(merged_test_dict.values()))\n","x_dev = np.array(list(merged_dev_dict.values()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yGaWk3rG1BA"},"outputs":[],"source":["del(merged_train_dict)\n","del(merged_test_dict)\n","del(merged_dev_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHDO5JA0l5m4"},"outputs":[],"source":["def data_handling(x, y):\n","\n","    for i in range(len(x)):\n","        x[i] = np.ravel(x[i])\n","\n","    max = -1\n","    for i in range(len(y)):\n","        if len(y[i]) > max:\n","            max = len(y[i])\n","    \n","    for i in range(len(x)):\n","        length = max - len(x[i])\n","        x[i] = np.pad(x[i], (0, length), 'constant')\n","        del(length)\n","\n","    arr = np.array([])\n","    for element in x:\n","        arr = np.concatenate((arr, element))\n","        del(element)\n","    \n","    del(x)\n","\n","    return arr, max"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3RtEIgfAbYt"},"outputs":[],"source":["# x_train_1 = x_train[0:81] \n","# x_train_2 = x_train[81:163]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gfoeQG0BE1G"},"outputs":[],"source":["# arr_1, max_train = data_handling(x_train_1, x_train)\n","# del(x_train_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GH6EnH8EDmNa"},"outputs":[],"source":["# arr_2, max_train = data_handling(x_train_2, x_train)\n","# del(x_train_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POMsI3FGujNn"},"outputs":[],"source":["# del(x_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Cqv7kTPu0z3"},"outputs":[],"source":["# arr_1 = np.concatenate((arr_1, arr_2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLlTBnEyvKue"},"outputs":[],"source":["# del(arr_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWVM4Y-TEKiL"},"outputs":[],"source":["arr_4, max_dev = data_handling(x_dev, x_dev)\n","print(x_dev[0].shape)\n","del(x_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJJAfkxIEDqe"},"outputs":[],"source":["# arr_3, max_test = data_handling(x_test, x_test)\n","# del(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpR7GirXw6uI"},"outputs":[],"source":["# x_train = arr_1.reshape(163, int(max_train/49), 49)\n","# del(arr_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8NZ_LNrxRgk"},"outputs":[],"source":["# x_test = arr_3.reshape(56, int(max_test/49), 49)\n","# del(arr_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8L6R1qAEyZi7"},"outputs":[],"source":["x_dev = arr_4.reshape(56, int(max_dev/49), 49)\n","del(arr_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMPaDZT_ygcN"},"outputs":[],"source":["# del(max_train)\n","# del(max_test)\n","del(max_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VZPmpHCyjzq"},"outputs":[],"source":["# print(x_train.shape)\n","# print(x_test.shape)\n","print(x_dev.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DVevR0h8fqY"},"outputs":[],"source":["# y_train = np.array(y_train)\n","# y_test = np.array(y_test)\n","y_dev = np.array(y_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VncfykfCUUqP"},"outputs":[],"source":["# create audio directory\n","out_dir = '/content/drive/MyDrive/Colab Notebooks/Depression Analysis/Data'\n","vid_features_dir = os.path.join(out_dir, 'aud_features_OpenSMILE2.3.0_mfcc')\n","if not os.path.exists(vid_features_dir):\n","    os.makedirs(vid_features_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQ7HVkJgXSpi"},"outputs":[],"source":["%ls\n","%cd /aud_features_OpenSMILE2.3.0_mfcc\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmyN62MLW1-E"},"outputs":[],"source":["# filename = 'x_train_OpenSMILE2.3.0_mfcc'\n","# np.savetxt('x_train_OpenSMILE2.3.0_mfcc', x_train.reshape(x_train.shape[0], -1), delimiter=',')\n","# del(x_train)\n","\n","# filename = 'x_test_OpenSMILE2.3.0_mfcc'\n","# np.savetxt('x_test_OpenSMILE2.3.0_mfcc', x_test.reshape(x_test.shape[0], -1), delimiter=',')\n","# del(x_test)\n","\n","# filename = 'x_dev_OpenSMILE2.3.0_mfcc'\n","# np.savetxt('x_dev_OpenSMILE2.3.0_mfcc', x_dev.reshape(x_dev.shape[0], -1), delimiter=',')\n","# del(x_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCcPkXoOgW9Q"},"outputs":[],"source":["filename = 'y_train_OpenSMILE2.3.0_mfcc'\n","np.savetxt('y_train_OpenSMILE2.3.0_mfcc', y_train.reshape(y_train.shape[0], -1), delimiter=',')\n","\n","filename = 'y_test_OpenSMILE2.3.0_mfcc'\n","np.savetxt('y_test_OpenSMILE2.3.0_mfcc', y_test.reshape(y_test.shape[0], -1), delimiter=',')\n","\n","filename = 'y_dev_OpenSMILE2.3.0_mfcc'\n","np.savetxt('y_dev_OpenSMILE2.3.0_mfcc', y_dev.reshape(y_dev.shape[0], -1), delimiter=',')"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1xEFfJ1HzMJo_EDHogSAcUu68PlxEg9JH","authorship_tag":"ABX9TyMvYGo61gJtJPhhrKgfTeLk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}